[2025-02-06T18:37:30.618+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-02-06T18:37:30.636+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_dag_incremental.transform_and_load manual__2025-02-06T18:22:38.992765+00:00 [queued]>
[2025-02-06T18:37:30.650+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_dag_incremental.transform_and_load manual__2025-02-06T18:22:38.992765+00:00 [queued]>
[2025-02-06T18:37:30.650+0000] {taskinstance.py:2866} INFO - Starting attempt 2 of 2
[2025-02-06T18:37:30.667+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): transform_and_load> on 2025-02-06 18:22:38.992765+00:00
[2025-02-06T18:37:30.680+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=278) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-02-06T18:37:30.681+0000] {standard_task_runner.py:72} INFO - Started process 280 to run task
[2025-02-06T18:37:30.682+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_dag_incremental', 'transform_and_load', 'manual__2025-02-06T18:22:38.992765+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/etl.py', '--cfg-path', '/tmp/tmp0h7b6evl']
[2025-02-06T18:37:30.684+0000] {standard_task_runner.py:105} INFO - Job 506: Subtask transform_and_load
[2025-02-06T18:37:30.742+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_dag_incremental.transform_and_load manual__2025-02-06T18:22:38.992765+00:00 [running]> on host f34e19f1f8c5
[2025-02-06T18:37:30.825+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_dag_incremental' AIRFLOW_CTX_TASK_ID='transform_and_load' AIRFLOW_CTX_EXECUTION_DATE='2025-02-06T18:22:38.992765+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-06T18:22:38.992765+00:00'
[2025-02-06T18:37:30.826+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-02-06T18:37:30.826+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-02-06T18:37:30.827+0000] {logging_mixin.py:190} INFO - Current task name:transform_and_load state:running start_date:2025-02-06 18:37:30.637589+00:00
[2025-02-06T18:37:30.827+0000] {logging_mixin.py:190} INFO - Dag name:etl_dag_incremental and current dag run status:running
[2025-02-06T18:37:30.827+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-02-06T18:37:31.214+0000] {etl.py:237} INFO - Unified transactions count: 15749
[2025-02-06T18:37:31.217+0000] {etl.py:242} INFO - Custumers transactions count: 15749
[2025-02-06T18:37:31.217+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.12.8, Platform: Linux-6.9.3-76060903-generic-x86_64-with-glibc2.36
[2025-02-06T18:37:31.218+0000] {connection.py:1197} INFO - Connecting to GLOBAL Snowflake domain
[2025-02-06T18:37:31.219+0000] {connection.py:1278} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-02-06T18:37:48.851+0000] {connection.py:789} INFO - closed
[2025-02-06T18:37:48.935+0000] {connection.py:795} INFO - No async queries seem to be running, deleting session
[2025-02-06T18:37:49.028+0000] {etl.py:300} ERROR - Error: 100038 (22018): 01ba377d-0000-d5b4-0000-00018dde16a5: Numeric value 'Connecticut' is not recognized
[2025-02-06T18:37:49.029+0000] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl.py", line 271, in transform_and_load
    cursor.executemany(insert_orders_sql, all_values)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1403, in executemany
    self.execute(command, **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100038 (22018): 01ba377d-0000-d5b4-0000-00018dde16a5: Numeric value 'Connecticut' is not recognized
[2025-02-06T18:37:49.042+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-02-06T18:37:49.042+0000] {logging_mixin.py:190} INFO - Task start:2025-02-06 18:37:30.637589+00:00 end:2025-02-06 18:37:49.041739+00:00 duration:18.40415
[2025-02-06T18:37:49.043+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): transform_and_load> dag:<DAG: etl_dag_incremental> dagrun:<DagRun etl_dag_incremental @ 2025-02-06 18:22:38.992765+00:00: manual__2025-02-06T18:22:38.992765+00:00, state:running, queued_at: 2025-02-06 18:22:39.024950+00:00. externally triggered: True>
[2025-02-06T18:37:49.043+0000] {logging_mixin.py:190} INFO - Failure caused by 100038 (22018): 01ba377d-0000-d5b4-0000-00018dde16a5: Numeric value 'Connecticut' is not recognized
[2025-02-06T18:37:49.043+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_dag_incremental, task_id=transform_and_load, run_id=manual__2025-02-06T18:22:38.992765+00:00, execution_date=20250206T182238, start_date=20250206T183730, end_date=20250206T183749
[2025-02-06T18:37:49.058+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-02-06T18:37:49.059+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 506 for task transform_and_load (100038 (22018): 01ba377d-0000-d5b4-0000-00018dde16a5: Numeric value 'Connecticut' is not recognized; 280)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl.py", line 271, in transform_and_load
    cursor.executemany(insert_orders_sql, all_values)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1403, in executemany
    self.execute(command, **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100038 (22018): 01ba377d-0000-d5b4-0000-00018dde16a5: Numeric value 'Connecticut' is not recognized
[2025-02-06T18:37:49.121+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-02-06T18:37:49.142+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-06T18:37:49.145+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
